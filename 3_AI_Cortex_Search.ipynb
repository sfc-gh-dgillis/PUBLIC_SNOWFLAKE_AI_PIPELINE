{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "clmtctpm2wi4vbmmfdxb",
   "authorId": "217400574159",
   "authorName": "JHEISLER",
   "authorEmail": "john.heisler@snowflake.com",
   "sessionId": "849a11c5-27fe-4853-9600-6a04c49752ce",
   "lastEditTime": 1745462436778
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18239d9e-e562-47a0-9b99-d83d089db6f2",
   "metadata": {
    "name": "_0_md_summary",
    "collapsed": false
   },
   "source": "# **SNOWFLAKE CORTEX SEARCH FINANCIAL SERVICES DEMO**\n## Authors: John Heisler, Garrett Frere\nIn this demo, using [Snowflake Cortex](https://www.snowflake.com/en/data-cloud/cortex/), we will build an RAG-powered chat interface.\n\n### RAG\nWe'll learn how to extract raw text from a PDF, chunk the raw text, perform prompt engineering, pass custom prompts and data to a large language model, and use Cortex Search to both handle our embeddings and retreval all without leaving Snowflake.\n\nSpecifically, we will be taking on the role of an AI Engineer who is working closely with a portfolio team at an asset manager. The portfolio team would like to deepen their comprehension of Federal Open Market Committee (FOMC) statements and meeting minutes. The FOMC determines the direction of monetary policy by directing open market operations. Ultimately the portfolio team would like an interface to ask and answer specific questions of a document wihtout searching throughout the text.\n\n## Steps: \n1. Extract the text from our PDFs\n2. Chunk the text from the PDFs\n3. Create a Cortex Search Service to handle the vectorization and retreival.\n4. Create a Chat interface with Streamlit in Snowflake.\n\n**IMPORTANT:** This is meant to be a companion to the FSI_Cortex_AI_Pipeline.ipynb also in this repository. \n\n\n# üõë BEFORE YOU START üõë\n\n[Load the PDF files](https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage-ui#upload-files-onto-a-named-internal-stage) into GEN_AI_FSI.FOMC.FED_PDF_SERVER_SIDE."
  },
  {
   "cell_type": "code",
   "id": "383ef196-bece-42b6-afb5-259eb90011dd",
   "metadata": {
    "language": "python",
    "name": "_0_py_setup_shop"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.core import Root\nimport streamlit as st\nimport json as json\nimport pandas as pd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8b3df6a-2005-444f-9f36-edf5cc0d808a",
   "metadata": {
    "name": "_1_md_parse_pdf",
    "collapsed": false
   },
   "source": "# Step 1: Ingest PDF Text\nUsing the [PARSE_DOCUMENT](https://docs.snowflake.com/en/sql-reference/functions/parse_document-snowflake-cortex) function, we'll extract the text out of the PDFs in our stage. We're retaining the mardown here to later use in our [chunking strategy](https://www.snowflake.com/en/engineering-blog/impact-retrieval-chunking-finance-rag/)."
  },
  {
   "cell_type": "code",
   "id": "06f8db36-56a2-41b2-928f-1c1e84c9638b",
   "metadata": {
    "language": "sql",
    "name": "_1_py_parse_document"
   },
   "outputs": [],
   "source": "--create a asequence for our table\nCREATE OR REPLACE SEQUENCE GEN_AI_FSI.FOMC.PDF_SEQ START = 1 INCREMENT = 1;\n\n--create the table if it aint there. Clear it out if it is.\nCREATE OR REPLACE TABLE GEN_AI_FSI.FOMC.PDF_FULL_TEXT_MARKDOWN_AWARE (\n        ID INT,\n        RELATIVE_PATH VARCHAR, \n        FILE_DATE DATE, \n        TEXT VARCHAR);\n\n--insert our data into the table\nINSERT INTO GEN_AI_FSI.FOMC.PDF_FULL_TEXT_MARKDOWN_AWARE (\n    WITH cte AS \n    (SELECT\n        GEN_AI_FSI.FOMC.PDF_SEQ.NEXTVAL as ID,\n        RELATIVE_PATH,\n        TRY_TO_DATE(REGEXP_SUBSTR (RELATIVE_PATH, '\\\\d{8}'),'YYYYMMDD') as FILE_DATE,\n        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n            @GEN_AI_FSI.FOMC.FED_PDF_SERVER_SIDE,\n            relative_path,\n            {'mode': 'LAYOUT'}):content AS TEXT\n    FROM DIRECTORY( @GEN_AI_FSI.FOMC.FED_PDF_SERVER_SIDE) ) \n    \n    SELECT \n        ID, \n        RELATIVE_PATH, \n        FILE_DATE,\n        trim(TEXT, '\"') AS TEXT\n    FROM CTE\n    );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3702f0db-5abc-491a-aa57-891896cfa10b",
   "metadata": {
    "name": "_2_md_chunking",
    "collapsed": false
   },
   "source": "# RAG: Build the Chunk Table\nUsing [SPLIT_TEXT_RECURSIVE_CHARACTER](https://docs.snowflake.com/en/sql-reference/functions/split_text_recursive_character-snowflake-cortex) SQL function, we chunk the markdown PDF text into chunks that parse based on markdown, not just size and overlap. "
  },
  {
   "cell_type": "code",
   "id": "81fba9c9-2f54-4f81-8e61-de2d745a63b4",
   "metadata": {
    "language": "sql",
    "name": "_2_py_chunk_text"
   },
   "outputs": [],
   "source": "--create the table if it aint there. Clear it out if it is.\nCREATE OR REPLACE TABLE \n    GEN_AI_FSI.FOMC.PDF_CHUNKS_MARKDOWN_AWARE (\n        ID INT,\n        RELATIVE_PATH VARCHAR, \n        FILE_DATE DATE,\n        CHUNK VARCHAR);\n\nINSERT INTO GEN_AI_FSI.FOMC.PDF_CHUNKS_MARKDOWN_AWARE(\n    SELECT\n        t.ID,\n        t.RELATIVE_PATH,\n        t.FILE_DATE,\n        CHUNKS.VALUE AS CHUNK\n    FROM\n        FOMC.PDF_FULL_TEXT_MARKDOWN_AWARE t ,\n        LATERAL FLATTEN( input =>   SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n            text,\n            'markdown',\n            500, \n            150\n             )) CHUNKS);\n\nSELECT TOP 5 * FROM GEN_AI_FSI.FOMC.PDF_CHUNKS_MARKDOWN_AWARE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b95175d3-e4c5-47aa-b21a-e504b6ac6e7f",
   "metadata": {
    "collapsed": false,
    "name": "_3_md_search_service"
   },
   "source": "# RAG: Create a Cortex Search Service\n\nCortex Search enables low-latency, high-quality ‚Äúfuzzy‚Äù search over your Snowflake data. Cortex Search powers a broad array of search experiences for Snowflake users including Retrieval Augmented Generation (RAG) applications leveraging Large Language Models (LLMs).\n\nWe'll use this service later to power our RAG application. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576cec9-f819-4598-951a-b660a2a977e9",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "_3_sql_search_service"
   },
   "outputs": [],
   "source": "--create a cortex Search Service \nCREATE OR REPLACE CORTEX SEARCH SERVICE GEN_AI_FSI.FOMC.SEARCH_FED_MARKDOWN_AWARE\n    ON CHUNK\n    ATTRIBUTES ID, FILE_DATE\n    WAREHOUSE = FED_GEN_AI\n    TARGET_LAG = '30 days'\n    AS (\n        SELECT \n            ID,\n            FILE_DATE::string as FILE_DATE,\n            CHUNK AS CHUNK  \n        FROM GEN_AI_FSI.FOMC.PDF_CHUNKS_MARKDOWN_AWARE);"
  },
  {
   "cell_type": "markdown",
   "id": "37b0e39c-62d3-494f-95ba-8279a88eedae",
   "metadata": {
    "collapsed": false,
    "name": "_4_md_streamlit"
   },
   "source": "# RAG: FOMC Chat Interface\n* We're leveraging our Cortex Search service enabling users to ask targeted questions of the documents in their stage.\n* A robust chat interface could be built to handle this. For the demo, we've got a bare bones interaction.\n    * You can drop this code in a stand alone streamlit in snowflake for the full expereince. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395e7b9-fb06-4cb0-ac10-ff007345e0fa",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "_4_py_streamlit"
   },
   "outputs": [],
   "source": "#get our session\nsession = get_active_session()\n\n# access search service through Python API\nroot = Root(session)\n\nsearch_service = (root\n                  .databases[\"GEN_AI_FSI\"]\n                  .schemas[\"FOMC\"]\n                  .cortex_search_services[\"SEARCH_FED_MARKDOWN_AWARE\"]    \n)\n\n#create a function to generate response\ndef complete_cs(model_name, prompt):\n    cmd = f\"\"\"SELECT SNOWFLAKE.CORTEX.TRY_COMPLETE('{model_name}','{prompt}') as response\"\"\"\n    df_response = session.sql(cmd).collect()\n    response = df_response[0].RESPONSE\n    return response\n\n\n#get FOMC files\ndatabase = 'GEN_AI_FSI'\nschema = 'FOMC'\n\n#USER INPUT: select time frame\nquery_document_dates = f\"\"\"SELECT DISTINCT FILE_DATE FROM {database}.{schema}.PDF_CHUNKS_MARKDOWN_AWARE order by file_date desc;\"\"\"\ndf_document_dates = session.sql(query_document_dates).to_pandas()\n\n#USER INPUT: select model\ndf_models = [\n    \"claude-3-5-sonnet\",\n    \"deepseek-r1\",\n    \"gemma-7b\",\n    \"jamba-1.5-large\",\n    \"jamba-1.5-mini\",\n    \"jamba-instruct\",\n    \"llama2-70b-chat\",\n    \"llama3-70b\",\n    \"llama3-8b\",\n    \"llama3.1-405b\",\n    \"llama3.1-70b\",\n    \"llama3.1-8b\",\n    \"llama3.2-1b\",\n    \"llama3.2-3b\",\n    \"llama3.3-70b\",\n    \"llama4-maverick\",\n    \"llama4-scout\",\n    \"mistral-7b\",\n    \"mistral-large\",\n    \"mistral-large2\",\n    \"reka-core\",\n    \"reka-flash\",\n    \"snowflake-arctic\",\n    \"snowflake-llama-3.1-405b\",\n    \"snowflake-llama-3.3-70b\"\n]\n\n#USER INPUT: display\ncol1, col2 = st.columns(2)\nwith col1:\n    user_input_date = st.selectbox(\"Select Document Date\", df_document_dates, key=\"CS_date_select_box\")\nwith col2: \n    user_input_model = st.selectbox(\"Select Model\", df_models, key=\"CS_model_select_box\")\n\n#Generate a response\nuser_input_question = st.text_input(\"Ask me a question\")\n\nask= st.button(\"Ask\", key = \"button_ask\")\nif ask: \n    #get the cunks that are relevant to the question\n    response = search_service.search(\n        user_input_question,\n        columns=[\"ID\", \"FILE_DATE\", \"CHUNK\"],\n        filter={\"@eq\": {\"FILE_DATE\": f\"\"\"{user_input_date}\"\"\"} },\n        limit=5,\n    ).to_json()\n\n    #st.json(response)\n    # Parse the JSON5 string\n    context_chunks = json.loads(response)\n    \n    #transform the data into a single string\n    context_full = \"\"\n    for chunk in context_chunks['results']:\n        context_full += chunk['CHUNK'] + \" \"\n    context_full = context_full.replace(\"'\",\"\").replace('\"','')\n\n    #build our prompt\n    cs_prompt = f'''\n            Role: You are an expert Senior Economist deeply knowledgeable on Federal Reserve documents and guidance including FOMC or Federal Open Market Committee \n            meeting minutes and communications. You are an expert in interpreting and answering investment-related questions based on meeting minutes and communications \n            which you are provided as context with each question.\n            \n            Data: You are provided with relevant text of a Federal Reserve Guidance or FOMC meeting notes relenavt to the question asked. \n            These meeting notes are generally released before the Federal Reserve takes action on economic policy.\n            \n            Task: Follow these instructions,\n            1) Answer the question based on the context. \n            2) Be terse and do not consider information outside what you have been provided in the question and context.\n            \n            Output: produce thourough, valid, gramtically correct, and concise response in a professional tone. Please do not preface your response. also provide the document and location you used to answer the question.\n            Context: {context_full}\n            Question: Based on documents released on this date {user_input_date}, {user_input_question} \n            '''\n\n    data = complete_cs(user_input_model, cs_prompt)\n    \n    with st.chat_message(\"model\", avatar =\"assistant\"):\n        st.write(data)"
  }
 ]
}